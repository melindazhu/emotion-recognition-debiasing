{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "n6dDeaQZYiMP",
        "HGgRIWc2bvXM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Inverse frequency reweighting and adversarial debiasing\n",
        "\n"
      ],
      "metadata": {
        "id": "UIQ3Wv7zXG5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing (repeated from baseline)"
      ],
      "metadata": {
        "id": "LRJKTxYfXRuw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBAgLtpwW_99"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision numpy matplotlib seaborn scikit-learn facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "jlTPNOdmXEoS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ref: https://www.kaggle.com/datasets/shuvoalok/raf-db-dataset\n",
        "# do this so we don't have to upload the zip file manually every time we run this notebook\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"shuvoalok/raf-db-dataset\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6yfZ1luXUNG",
        "outputId": "bd63c434-3bd0-419e-ee1e-359b0b13bcfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shuvoalok/raf-db-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37.7M/37.7M [00:00<00:00, 119MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/shuvoalok/raf-db-dataset/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "destination_dir = '/content/raf-db'\n",
        "shutil.copytree(path, destination_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i8eMqokyXVb7",
        "outputId": "c313a5a2-5fd9-4539-ea5a-cf230993aa3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/raf-db'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load labels from train/test\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "train_labels = pd.read_csv(\"raf-db/train_labels.csv\")\n",
        "test_labels = pd.read_csv(\"raf-db/test_labels.csv\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)), # for ResNet\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "class RAFDBDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        # need to take into account the file structure: e.g. DATASET/train/1/train_0001_aligned.jpg\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # file walkthrough: with some help from LLM\n",
        "        for label in sorted(os.listdir(root_dir)):\n",
        "            label_path = os.path.join(root_dir, label)\n",
        "            if os.path.isdir(label_path): # should be subdirectory\n",
        "                for img_name in os.listdir(label_path):\n",
        "                    self.image_paths.append(os.path.join(label_path, img_name))\n",
        "                    self.labels.append(int(label) - 1) # convert to zero indexing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "train_dir = \"raf-db/DATASET/train\"\n",
        "test_dir = \"raf-db/DATASET/test\"\n",
        "\n",
        "train_dataset = RAFDBDataset(root_dir=train_dir, transform=transform)\n",
        "test_dataset = RAFDBDataset(root_dir=test_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "tzUcdv6XXWbk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# model (copied from baseline notebook) with dropout, early stopping, weight decay\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# with dropout\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=7, dropout_prob=0.5):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(64, 64, 2)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(ResNetBlock(in_channels, out_channels, stride, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResNetBlock(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "RvKtoOGaXsIs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inverse frequency reweighting"
      ],
      "metadata": {
        "id": "29oz6e0EX2kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# race labels from the FairFace embeddings task\n",
        "raf_race_labels_train = np.load('raf_race_labels_train.npy', allow_pickle=True).item()\n",
        "\n",
        "print(f\"Total training samples with race labels: {len(raf_race_labels_train)}\")\n",
        "print(\"Sample:\", list(raf_race_labels_train.items())[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfqYZ_lUX38K",
        "outputId": "c97bc5c5-64b6-44d4-af36-7ded0a55787f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples with race labels: 12271\n",
            "Sample: [('train_08777_aligned.jpg', np.str_('White')), ('train_04175_aligned.jpg', np.str_('White')), ('train_06866_aligned.jpg', np.str_('Latino')), ('train_05827_aligned.jpg', np.str_('Latino')), ('train_08913_aligned.jpg', np.str_('Middle_Eastern'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compute inverse frequency weights"
      ],
      "metadata": {
        "id": "n6dDeaQZYiMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# no. samples per race\n",
        "race_counts = Counter(raf_race_labels_train.values())\n",
        "print(\"Race counts:\", race_counts)\n",
        "\n",
        "total_samples = sum(race_counts.values())\n",
        "num_races = len(race_counts)\n",
        "\n",
        "# compute inverse frequency weights\n",
        "race_weights = {race: total_samples / (num_races * count) for race, count in race_counts.items()}\n",
        "print(\"Race weights (inverse frequency):\", race_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFS6dstXYkQK",
        "outputId": "6de4b143-5d65-4464-914a-1d3ae9dabdd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Race counts: Counter({np.str_('White'): 7525, np.str_('Latino'): 2401, np.str_('Black'): 1178, np.str_('Middle_Eastern'): 674, np.str_('Asian'): 493})\n",
            "Race weights (inverse frequency): {np.str_('White'): 0.32613953488372094, np.str_('Latino'): 1.0221574344023323, np.str_('Middle_Eastern'): 3.641246290801187, np.str_('Black'): 2.0833616298811544, np.str_('Asian'): 4.978093306288033}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load dataset and train"
      ],
      "metadata": {
        "id": "HGgRIWc2bvXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modify the original RAFDBDataset class to also include race labels so we can implement the debiasing techniques\n",
        "\n",
        "class RAFDBTrainDatasetWithRace(Dataset):\n",
        "    def __init__(self, root_dir, emotions, race_labels_dict, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.emotions = emotions\n",
        "        self.race_labels_dict = race_labels_dict\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.filenames = []\n",
        "        self.race_labels = []\n",
        "\n",
        "        for emotion in emotions:\n",
        "            emotion_folder = os.path.join(root_dir, emotion)\n",
        "            for img_name in os.listdir(emotion_folder):\n",
        "                img_path = os.path.join(emotion_folder, img_name)\n",
        "\n",
        "                self.image_paths.append(img_path)\n",
        "                self.labels.append(int(emotion) - 1)  # 0-indexed labels\n",
        "                self.filenames.append(img_name)\n",
        "\n",
        "                race_label = race_labels_dict.get(img_name, \"Unknown\")\n",
        "                self.race_labels.append(race_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        filename = self.filenames[idx]\n",
        "        race_label = self.race_labels[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label, filename, race_label"
      ],
      "metadata": {
        "id": "lq60GE75YsaY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'raf-db/DATASET/train'\n",
        "train_emotions = sorted(os.listdir(train_dir), key=lambda x: int(x))\n",
        "print(\"train emotions:\", train_emotions)\n",
        "\n",
        "train_dataset = RAFDBTrainDatasetWithRace(\n",
        "    root_dir=train_dir,\n",
        "    emotions=train_emotions,\n",
        "    race_labels_dict=raf_race_labels_train,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "ECoOGfj8a3dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# params copied over from baseline training w/ dropout, early stopping, weight decay\n",
        "num_classes = 7\n",
        "num_epochs = 15\n",
        "patience = 5 # early stopping\n",
        "dropout_prob = 0.5\n",
        "weight_decay = 1e-4\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet(num_classes=num_classes, dropout_prob=dropout_prob).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with tqdm(train_loader, desc=f\"epoch [{epoch+1}/{num_epochs}]\", unit=\"batch\") as t:\n",
        "        for images, labels, filenames, race_labels in t:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss_per_sample = criterion(outputs, labels)  # shape: (batch_size,)\n",
        "\n",
        "            # Convert race labels to their weights\n",
        "            batch_weights = torch.tensor([race_weights[race] for race in race_labels], dtype=torch.float32).to(device)\n",
        "\n",
        "            # Apply race weights to the loss\n",
        "            weighted_loss = (loss_per_sample * batch_weights).mean()\n",
        "\n",
        "            weighted_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += weighted_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            t.set_postfix(loss=running_loss / (total / 32), acc=correct / total)\n",
        "\n",
        "torch.save(model.state_dict(), 'inverse_freq.pth')"
      ],
      "metadata": {
        "id": "zG4j-dVdbVx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate (copied from baseline ResNet code)"
      ],
      "metadata": {
        "id": "12WHKF4zcH28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# dependency on the first FairFace race annotation task\n",
        "race_labels_test = np.load('/content/raf_race_labels_test.npy', allow_pickle=True).item()"
      ],
      "metadata": {
        "id": "7nhdikjDcalV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "best_model = ResNet(num_classes=7).to(device)\n",
        "best_model.load_state_dict(torch.load(\"inverse_freq.pth\", map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "# Dictionaries to store predictions and ground truths grouped by race\n",
        "race_predictions = defaultdict(list)\n",
        "race_ground_truths = defaultdict(list)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, emotion_labels, filenames in test_loader:\n",
        "        images = images.to(device)\n",
        "        emotion_labels = emotion_labels.to(device)\n",
        "        outputs = best_model(images)\n",
        "        _, predicted_emotions = torch.max(outputs, 1)\n",
        "\n",
        "        for idx in range(len(filenames)):\n",
        "            filename = filenames[idx]\n",
        "\n",
        "            # match race_labels_test keys\n",
        "            normalized_filename = filename\n",
        "            if not normalized_filename.endswith('_aligned.jpg'):\n",
        "                normalized_filename = normalized_filename.replace('.jpg', '_aligned.jpg')\n",
        "\n",
        "            race = race_labels_test.get(normalized_filename, \"Unknown\")\n",
        "            if race == \"Unknown\":\n",
        "                print(f\"race label missing for {normalized_filename}\")\n",
        "\n",
        "            race_predictions[race].append(predicted_emotions[idx].cpu().item())\n",
        "            race_ground_truths[race].append(emotion_labels[idx].cpu().item())\n",
        "\n",
        "emotion_classes = [\"surprise\", \"fear\", \"disgust\", \"happiness\", \"sadness\", \"anger\", \"neutral\"]\n",
        "labels_used = list(range(len(emotion_classes)))  # [0, 1, 2, 3, 4, 5, 6]"
      ],
      "metadata": {
        "id": "NI1NMX1LcJ1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "races = []\n",
        "accuracies = []\n",
        "standard_errors = []\n",
        "\n",
        "for race in race_predictions.keys():\n",
        "    y_true = race_ground_truths[race]\n",
        "    y_pred = race_predictions[race]\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    n_samples = len(y_true)\n",
        "    # error bars\n",
        "    se = np.sqrt(acc * (1 - acc) / n_samples)\n",
        "\n",
        "    races.append(race)\n",
        "    accuracies.append(acc)\n",
        "    standard_errors.append(se)\n",
        "\n",
        "    # got some help from LLM here for how to nicely format the output in a tabular format\n",
        "    # using classification_report.\n",
        "    print(f\"\\n=== Race: {race} ===\")\n",
        "    print(f\"Samples: {n_samples}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Standard Error: {se:.4f}\")\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        labels=labels_used,\n",
        "        target_names=emotion_classes,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(races, accuracies, yerr=standard_errors, capsize=5, alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Race\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy per race\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JtL6YndEcdyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adversarial debiasing"
      ],
      "metadata": {
        "id": "7HuhJOaAcj-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model setup"
      ],
      "metadata": {
        "id": "H_Kn4BWTcxdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "\n",
        "# got some help from ChatGPT since this was a more unknown component compared to\n",
        "# the ResNet setup. Literature also didn't provide a specific implementation.\n",
        "class GradientReversalFunction(Function):\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.view_as(x)\n",
        "\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg() * ctx.lambda_, None\n",
        "\n",
        "def grad_reverse(x, lambda_=1.0):\n",
        "    return GradientReversalFunction.apply(x, lambda_)"
      ],
      "metadata": {
        "id": "NoMVkwnkclXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use previously implemented ResNet as a basis, and make sure the output is 512d.\n",
        "# this will be used as the feature extractor that later feeds the output into\n",
        "# the emotion classifier and race classifier.\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, dropout_prob=0.5):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "\n",
        "        # using the same ResNet as before!\n",
        "        self.backbone = ResNet(dropout_prob=dropout_prob)\n",
        "        self.feature_dim = 512 # size of the feature representation / embedding\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        x = self.backbone.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "5YtwT0WKc9W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdversarialDebiasingModel(nn.Module):\n",
        "    def __init__(self, feature_extractor, num_emotions=7, num_races=7, lambda_adv=1.0):\n",
        "        super(AdversarialDebiasingModel, self).__init__()\n",
        "\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.lambda_adv = lambda_adv\n",
        "        self.emotion_classifier = nn.Linear(self.feature_extractor.feature_dim, num_emotions)\n",
        "        # adversary. keep the model simple so training doesn't take exponentially longer\n",
        "        # (might run out of GPU credits)\n",
        "        self.race_classifier = nn.Sequential(\n",
        "            nn.Linear(self.feature_extractor.feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_races)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        emotion_logits = self.emotion_classifier(features)\n",
        "        reversed_features = grad_reverse(features, self.lambda_adv)\n",
        "        race_logits = self.race_classifier(reversed_features)\n",
        "\n",
        "        return emotion_logits, race_logits"
      ],
      "metadata": {
        "id": "sYAI7hZcdRbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the model"
      ],
      "metadata": {
        "id": "Mj11637QdrhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "race_classes = sorted(set(raf_race_labels_train.values()))\n",
        "race_to_index = {race: idx for idx, race in enumerate(race_classes)}"
      ],
      "metadata": {
        "id": "ijR4H4SPeCzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_emotions = 7\n",
        "num_races = len(set(raf_race_labels_train.values()))\n",
        "lambda_adv_start = 0.0\n",
        "lambda_adv_max = 1.0 # adversarial strength. gradually increase the lambda\n",
        "\n",
        "feature_extractor = ResNetFeatureExtractor(dropout_prob=0.5)\n",
        "adv_model = AdversarialDebiasingModel(feature_extractor, num_emotions, num_races, lambda_adv_start).to(device)\n",
        "\n",
        "emotion_criterion = nn.CrossEntropyLoss()\n",
        "race_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(adv_model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    adv_model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_emotion, correct_race = 0, 0\n",
        "    total_emotion, total_race = 0, 0\n",
        "\n",
        "    # gradually increase the adversarial strength\n",
        "    lambda_adv = min(lambda_adv_max, epoch / (num_epochs / 2))\n",
        "    adv_model.lambda_adv = lambda_adv\n",
        "\n",
        "    for images, emotion_labels, _, race_labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        emotion_labels = emotion_labels.to(device)\n",
        "        race_indices = torch.tensor([race_to_index[r] for r in race_labels], dtype=torch.long).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        emotion_logits, race_logits = adv_model(images)\n",
        "        loss_emotion = emotion_criterion(emotion_logits, emotion_labels)\n",
        "        loss_race = race_criterion(race_logits, race_indices)\n",
        "\n",
        "        total_loss = loss_emotion + loss_race\n",
        "        total_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # for tracking / metrics\n",
        "        running_loss += total_loss.item()\n",
        "\n",
        "        _, pred_emotion = torch.max(emotion_logits, 1)\n",
        "        _, pred_race = torch.max(race_logits, 1)\n",
        "\n",
        "        correct_emotion += (pred_emotion == emotion_labels).sum().item()\n",
        "        total_emotion += emotion_labels.size(0)\n",
        "\n",
        "        correct_race += (pred_race == race_indices).sum().item()\n",
        "        total_race += race_indices.size(0)\n",
        "\n",
        "    emotion_acc = correct_emotion / total_emotion\n",
        "    race_acc = correct_race / total_race\n",
        "\n",
        "    # got some help from chatgpt for how to format this such that the training progress is clear.\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Lambda_adv: {lambda_adv:.2f} | Loss: {running_loss:.4f} | \"\n",
        "          f\"Emotion Acc: {emotion_acc:.4f} | Race Acc (adv): {race_acc:.4f}\")"
      ],
      "metadata": {
        "id": "HrD8bKaMdpk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(adv_model.state_dict(), \"adv_debias_model.pth\")"
      ],
      "metadata": {
        "id": "_9EuWe7QeBlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate (copied from previous eval code)"
      ],
      "metadata": {
        "id": "3rbn3agueKdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# dependency on the first FairFace race annotation task\n",
        "race_labels_test = np.load('/content/raf_race_labels_test.npy', allow_pickle=True).item()"
      ],
      "metadata": {
        "id": "e0g-1JrheH4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "best_model = ResNet(num_classes=7).to(device)\n",
        "best_model.load_state_dict(torch.load(\"inverse_freq.pth\", map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "# Dictionaries to store predictions and ground truths grouped by race\n",
        "race_predictions = defaultdict(list)\n",
        "race_ground_truths = defaultdict(list)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, emotion_labels, filenames in test_loader:\n",
        "        images = images.to(device)\n",
        "        emotion_labels = emotion_labels.to(device)\n",
        "        outputs = best_model(images)\n",
        "        _, predicted_emotions = torch.max(outputs, 1)\n",
        "\n",
        "        for idx in range(len(filenames)):\n",
        "            filename = filenames[idx]\n",
        "\n",
        "            # match race_labels_test keys\n",
        "            normalized_filename = filename\n",
        "            if not normalized_filename.endswith('_aligned.jpg'):\n",
        "                normalized_filename = normalized_filename.replace('.jpg', '_aligned.jpg')\n",
        "\n",
        "            race = race_labels_test.get(normalized_filename, \"Unknown\")\n",
        "            if race == \"Unknown\":\n",
        "                print(f\"race label missing for {normalized_filename}\")\n",
        "\n",
        "            race_predictions[race].append(predicted_emotions[idx].cpu().item())\n",
        "            race_ground_truths[race].append(emotion_labels[idx].cpu().item())\n",
        "\n",
        "emotion_classes = [\"surprise\", \"fear\", \"disgust\", \"happiness\", \"sadness\", \"anger\", \"neutral\"]\n",
        "labels_used = list(range(len(emotion_classes)))  # [0, 1, 2, 3, 4, 5, 6]"
      ],
      "metadata": {
        "id": "M9R6okiJeY__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "races = []\n",
        "accuracies = []\n",
        "standard_errors = []\n",
        "\n",
        "for race in race_predictions.keys():\n",
        "    y_true = race_ground_truths[race]\n",
        "    y_pred = race_predictions[race]\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    n_samples = len(y_true)\n",
        "    # error bars\n",
        "    se = np.sqrt(acc * (1 - acc) / n_samples)\n",
        "\n",
        "    races.append(race)\n",
        "    accuracies.append(acc)\n",
        "    standard_errors.append(se)\n",
        "\n",
        "    # got some help from LLM here for how to nicely format the output in a tabular format\n",
        "    # using classification_report.\n",
        "    print(f\"\\n=== Race: {race} ===\")\n",
        "    print(f\"Samples: {n_samples}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Standard Error: {se:.4f}\")\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        labels=labels_used,\n",
        "        target_names=emotion_classes,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(races, accuracies, yerr=standard_errors, capsize=5, alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Race\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy per race\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6--8BYkhehLa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}